---
title: "p8105_hw5_yf2605"
author: "Yi_Fang"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(
  theme_minimal() + 
    theme(
      legend.position = "bottom",
      plot.title = element_text(hjust = 0.5)
    )  
)
```

# Problem 1

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:

- create file path list and read data
- unnest the data
- separate file name into arm and id
- tidy the dataset, make the dataset longer with 1 column for week and 1 column for observation result 
- convert week into a factor variable with 8 levels
- select required columns: arm, id, week, result

```{r}
p1_df = 
  tibble(file_name = list.files(path="data/P1_data")) %>% 
  mutate(
    path = str_c("data/P1_data/", file_name),
    data = map(path, read_csv)
    ) %>% 
  unnest(data) %>% 
  separate(
    col = file_name, 
    into = c("arm","id","suffix"), 
    sep = "\\_|\\.", 
    remove = TRUE
    ) %>% 
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "result"
  ) %>% 
  mutate(week = as.factor(week)) %>% 
  select(arm, id, week, result)
```

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r}
p1_df %>%
  mutate(
    arm = ifelse(arm == "con", "Control", "Experimental")
  ) %>% 
  ggplot(
    aes(
      x = week, 
      y = result, 
      group = id)
    ) +
  geom_point()+
  geom_line()+
  facet_grid(. ~ arm)+
  labs(
    title = "Spaghetti plot for observation results on each subject over time by arm",
    x = "Week",
    y = "Result"
  )
  
```

- For the experimental group, the observation results seemed to increase over time.
- For the control group, there seemed to be no trend in the observation results over time.

# Problem 2

```{r}
homicide = read_csv("data/homicide-data.csv")
```

Description:
The raw data set contains `r ncol(homicide)` variables and `r nrow(homicide)` records.

* `r colnames(homicide)`


Create a city_state variable (e.g. “Baltimore, MD”)

```{r}
homicide = 
  homicide %>% 
  mutate(
    city_state = str_c(city, ", ", state)
  ) 
```

summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
city_sum = 
  homicide %>% 
  group_by(city_state) %>% 
  summarize(
    n_homicide = n(),
    n_unsolved = sum(disposition == "Closed without arrest" | 
                     disposition == "Open/No arrest")
  ) 
  
city_sum %>% knitr::kable()
```


For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; 

save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
baltimore_sum = 
  city_sum %>% 
  filter(city_state == "Baltimore, MD")

baltimore_result = 
  prop.test(
  x = baltimore_sum[['n_unsolved']], 
  n = baltimore_sum[['n_homicide']]
  ) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)

baltimore_result %>% knitr::kable(digits = 2)
```

Run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. 

Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
tidy_ptest = function(x, n){
  result_df = 
    prop.test(
      x = x, 
      n = n
    )%>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)

  result_df
}

city_result = 
  city_sum %>% 
  mutate(
    result_df = purrr::map2(
      .x = n_unsolved, 
      .y = n_homicide, 
      ~tidy_ptest(x = .x, n = .y)
    )
  ) %>% 
  unnest(result_df)

city_result %>% knitr::kable(digits = 2)
```

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. 

Organize cities according to the proportion of unsolved homicides.

```{r}
city_result %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(
    x = city_state,
    y = estimate
  ))+
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, 
                    ymax = conf.high
                    ))+
  labs(
    title = "Estimate and 95%CI for unsolved homicide in each city",
    x = "City, State",
    y = "Estimate"
  )+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

# Problem 3

Set the following design elements:

Fix n=30
Fix σ=5
Set μ=0. Generate 5000 datasets from the model

x∼Normal[μ,σ]

For each dataset, save μ^ and the p-value arising from a test of H:μ=0 using α=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.

```{r}
sim_fuc = function(x) {
  
  sim_data = function(mu) {
    
    data = tibble(
      x = rnorm(n = 30, mean = mu, sd = 5),
    )
    
    data
  }
  
  sim_df = 
    expand_grid(
      mu = x,
      iter = 1:5000
    ) %>% 
    mutate(
      data = map(mu, sim_data)
    )
  
  tidy_ttest = function(df) {
    
    test_result = 
      t.test(x=df[['x']], mu=0) %>% 
      broom::tidy() %>% 
      select(estimate, p.value)
    
    test_result
  }
  
  result_df = 
    sim_df %>% 
    mutate(
      result = map(data, tidy_ttest)
    ) %>% 
    unnest(result)

  result_df
}


sim_fuc(0)
```

Repeat the above for μ={1,2,3,4,5,6}

```{r}
sim_result = 
  expand_grid(
    iter = 0:6
  ) %>% 
  mutate(
    result = map(iter, sim_fuc)
  ) %>% 
  select(-iter) %>% 
  unnest(result) %>% 
  select(-iter)
```


**Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.**

```{r}
sim_result %>% 
  group_by(mu) %>% 
  summarize(
    n_test = n(),
    n_rejected = sum(p.value < 0.05),
    power = n_rejected/n_test
  ) %>% 
  ggplot(aes(
    x = mu,
    y = power
  ))+
  geom_point() +
  geom_line() +
  labs(
    title = "Statistical power by effect size",
    x = "Effect size",
    y = "Statistical power"
  )
```

Effect size is positively associated with statistical power.

**Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?**

```{r}
sim_result %>% 
  filter(p.value < 0.05) %>% 
  group_by(mu) %>% 
  summarize(
    average_mu_hat = mean(estimate) 
  ) %>% 
  ggplot(aes(
    x = mu,
    y = average_mu_hat
  ))+
  geom_point() +
  geom_line() +
  labs(
    title = "Average point estimate by true mean",
    x = "True mean",
    y = "Average point estimate"
  )
```


The sample average of point estimate across tests for which the null is rejected is approximately equal to the true value of μ, because 

- we simulated the data based on true mean
- we excluded the outliers whose hypothesis test result id fail to reject the null